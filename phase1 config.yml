version: '2'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    ports:
      - "32181:32181"
    healthcheck:
      test: ["CMD", "zookeeper-shell", "localhost:32181", "ruok"]
      interval: 30s          # Check every 30 seconds
      timeout: 10s           # Timeout after 10 seconds
      retries: 3             # Retry up to 3 times before marking as unhealthy
      start_period: 10s      # Allow up to 10 seconds for Zookeeper to start
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka-network

  kafka:
    image: confluentinc/cp-kafka:latest
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    hostname: kafka-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
    depends_on:
      - zookeeper
    networks:
      - kafka-network

  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "WARN"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_PLUGIN_PATH: "/usr/share/java"  # adjust path as necessary
      CONNECT_PLUGIN_DISCOVERY: "only_scan"  # This silences the warning
      CONNECT_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_CONNECT_CONFIG: "/usr/local/bin/create-connectors.sh"

    depends_on:
      - kafka
    networks:
      - kafka-network
    volumes:
      - ./create-connectors.sh:/usr/local/bin/create-connectors.sh
    entrypoint: ["/bin/bash", "-c", "/usr/local/bin/create-connectors.sh && /etc/confluent/docker/run"]

  mysql:
    image: mysql:latest
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: firstdb
      MYSQL_USER: my_user
      MYSQL_PASSWORD: password
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 5
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
    networks:
      - kafka-network

  postgres:
    image: postgres:latest
    environment:
      POSTGRES_USER: my_user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: seconddb
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U your_user"]
      interval: 30s
      timeout: 10s
      retries: 5
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - kafka-network
      
   filebeat:
    image: docker.elastic.co/beats/filebeat:7.10.1  # Use an appropriate version
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
    depends_on:
      - kafka
    networks:
      - kafka-network


networks:
  kafka-network:
    driver: bridge

volumes:
  mysql-data:
  postgres-data:

